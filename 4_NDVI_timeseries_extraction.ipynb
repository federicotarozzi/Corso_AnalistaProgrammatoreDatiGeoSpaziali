{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/federicotarozzi/Corso_AnalistaProgrammatoreDatiGeoSpaziali/blob/main/4_NDVI_timeseries_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e39299a",
      "metadata": {
        "id": "0e39299a"
      },
      "source": [
        "# Average field's NDVI estraction notebook\n",
        "from the NDVI satellite images, the average NDVI for each tomato-growing field will be extracted with this notebook. To do this, image processing is required to remove data influenced by the presence of clouds. Second, each polygon will be cropped to the image and the average NDVI for each date will be extracted."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecb16986",
      "metadata": {
        "id": "ecb16986"
      },
      "source": [
        "- shapefile (to transform with qGIS): https://agreagestione.regione.emilia-romagna.it/agrea-file/PianiColturaliAlfanumerici/\n",
        "- NDVI images: EO:CLMS:DAT:CLMS_GLOBAL_NDVI_300M_V1_10DAILY_NETCDF at https://www.wekeo.eu/data?view=viewer (Wekeo platform) from 1/04 - 30/09 : the growing period"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6694ea89",
      "metadata": {
        "id": "6694ea89"
      },
      "source": [
        "#### Import the library we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03bc0874",
      "metadata": {
        "tags": [],
        "id": "03bc0874",
        "outputId": "d60765b0-b6cf-4b82-b55c-a06777fa4b31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.environ['USE_PYGEOS'] = '0'\n",
        "\n",
        "import rasterio\n",
        "import fiona\n",
        "from shapely.geometry import shape, mapping, Polygon\n",
        "from shapely.wkt import loads\n",
        "from shapely import wkt\n",
        "from fiona.transform import transform_geom\n",
        "from rasterio.mask import mask\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import glob\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Disable the warning for invalid values encountered in casting\n",
        "np.seterr(invalid='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aefa4a6",
      "metadata": {
        "id": "8aefa4a6"
      },
      "source": [
        "#### Define the data paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99243e19",
      "metadata": {
        "id": "99243e19"
      },
      "outputs": [],
      "source": [
        "img_folder = \"Data/NDVI_data/piacenza/2019/NDVI\" # NDVI images folder\n",
        "qf_folder = \"Data/NDVI_data/piacenza/2019/QF\" # Quality flag images folder - cloud detection\n",
        "output_folder = \"Data/NDVI_data/piacenza/2019/NDVI_corrected\" #where to put the pocessed images\n",
        "shp = \"Data/NDVI_data/piacenza/2019/shapefile_input/pomodoro_campi50_2019.shp\" # shapefile with choosen fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71fad716",
      "metadata": {
        "id": "71fad716"
      },
      "outputs": [],
      "source": [
        "#select all the tiff images in the folders\n",
        "img_paths = glob.glob(os.path.join(img_folder, '*.tif'))\n",
        "qf_paths = glob.glob(os.path.join(qf_folder, '*.tif'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f272cce6",
      "metadata": {
        "id": "f272cce6",
        "outputId": "0ae46e65-c2e8-4d49-8d12-df47f117b874"
      },
      "outputs": [
        {
          "ename": "CRSError",
          "evalue": "The WKT could not be parsed. PROJ: internal_proj_create_from_database: /opt/conda/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCPLE_AppDefinedError\u001b[0m                      Traceback (most recent call last)",
            "File \u001b[0;32mfiona/crs.pyx:774\u001b[0m, in \u001b[0;36mfiona.crs.CRS.from_user_input\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mfiona/_err.pyx:280\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_ogrerr\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCPLE_AppDefinedError\u001b[0m: PROJ: internal_proj_create_from_database: /opt/conda/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mCRSError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m shapes \u001b[38;5;241m=\u001b[39m [feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m shapefile] \u001b[38;5;66;03m# geometry list\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Transform geometries to EPSG:32632\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# if I dont want the reshape\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m transformed_shapes \u001b[38;5;241m=\u001b[39m [transform_geom(shapefile_crs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPSG:32632\u001b[39m\u001b[38;5;124m\"\u001b[39m, shape) \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m shapes]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# For the creation of the dataframe extract properties and transformed geometries and reshape them in a readable format\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df_transformed_shapes \u001b[38;5;241m=\u001b[39m [reshape(transform_geom(shapefile_crs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPSG:32632\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m shapefile]\n",
            "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m shapes \u001b[38;5;241m=\u001b[39m [feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m shapefile] \u001b[38;5;66;03m# geometry list\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Transform geometries to EPSG:32632\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# if I dont want the reshape\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m transformed_shapes \u001b[38;5;241m=\u001b[39m [\u001b[43mtransform_geom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapefile_crs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEPSG:32632\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m shapes]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# For the creation of the dataframe extract properties and transformed geometries and reshape them in a readable format\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df_transformed_shapes \u001b[38;5;241m=\u001b[39m [reshape(transform_geom(shapefile_crs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPSG:32632\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m shapefile]\n",
            "File \u001b[0;32m/opt/conda/envs/ndvi/lib/python3.10/site-packages/fiona/transform.py:108\u001b[0m, in \u001b[0;36mtransform_geom\u001b[0;34m(src_crs, dst_crs, geom, antimeridian_cutting, antimeridian_offset, precision)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Function is implemented in the _transform C extension module.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(geom, (Geometry,) \u001b[38;5;241m+\u001b[39m DICT_TYPES):\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_transform_geom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdst_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeom\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mantimeridian_cutting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mantimeridian_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _transform_geom(\n\u001b[1;32m    118\u001b[0m         src_crs,\n\u001b[1;32m    119\u001b[0m         dst_crs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         precision,\n\u001b[1;32m    124\u001b[0m     )\n",
            "File \u001b[0;32mfiona/_transform.pyx:149\u001b[0m, in \u001b[0;36mfiona._transform._transform_geom\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mfiona/_transform.pyx:53\u001b[0m, in \u001b[0;36mfiona._transform._crs_from_crs\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mfiona/crs.pyx:776\u001b[0m, in \u001b[0;36mfiona.crs.CRS.from_user_input\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCRSError\u001b[0m: The WKT could not be parsed. PROJ: internal_proj_create_from_database: /opt/conda/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation."
          ]
        }
      ],
      "source": [
        "#define a funtion to find the geometry and save in WKT format (Well-Known Text)\n",
        "def reshape(geom):\n",
        "    return shape(geom).buffer(0).wkt\n",
        "\n",
        "\n",
        "# Read the shapefile\n",
        "with fiona.open(shp, \"r\") as shapefile:\n",
        "    shapefile_crs = shapefile.crs #defining the actual crs\n",
        "    shapes = [feature[\"geometry\"] for feature in shapefile] # geometry list\n",
        "\n",
        "    # Transform geometries to EPSG:32632\n",
        "    # if I dont want the reshape\n",
        "    transformed_shapes = [transform_geom(shapefile_crs, \"EPSG:32632\", shape) for shape in shapes]\n",
        "\n",
        "    # For the creation of the dataframe extract properties and transformed geometries and reshape them in a readable format\n",
        "    df_transformed_shapes = [reshape(transform_geom(shapefile_crs, \"EPSG:32632\", feature[\"geometry\"])) for feature in shapefile]\n",
        "    data = []\n",
        "    for feature, s in zip(shapefile, df_transformed_shapes):\n",
        "        properties = feature['properties']\n",
        "        data.append({'id': properties['id'], 'geometry': s, 'area': properties.get('area', None)})\n",
        "\n",
        "# Create a DataFrame\n",
        "polygon_df = pd.DataFrame(data)\n",
        "polygon_df['geometry'] = polygon_df['geometry'].astype(str)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(polygon_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63eca95e",
      "metadata": {
        "id": "63eca95e"
      },
      "source": [
        "#### Mask all the NDVI rasters with the Quality flag rasters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57aa780b",
      "metadata": {
        "id": "57aa780b"
      },
      "outputs": [],
      "source": [
        "#find the date of every images based on images names with lambda function\n",
        "get_date = lambda path: os.path.basename(path).split('_')[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76bc6985",
      "metadata": {
        "id": "76bc6985"
      },
      "outputs": [],
      "source": [
        "# Sort the image and qf files based on the parsed date\n",
        "sorted_img_paths = sorted(img_paths, key=lambda path: get_date(path))\n",
        "sorted_qf_paths = sorted(qf_paths, key=lambda path: get_date(path))\n",
        "\n",
        "# Print the sorted paths\n",
        "for img_path, qf_path in zip(sorted_img_paths, sorted_qf_paths):\n",
        "    # Read the image and quality files\n",
        "    with rasterio.open(img_path) as src_img, rasterio.open(qf_path) as src_qf:\n",
        "        #print(\"Raster CRS:\", src_img.crs)\n",
        "        profile = src_img.profile\n",
        "        nodata_value = profile.get('nodata')\n",
        "\n",
        "        # Mask the image and quality files with the shapefile\n",
        "        img, img_transform = mask(src_img, transformed_shapes, crop=True, filled=True, nodata=nodata_value)\n",
        "        qf, qf_transform = mask(src_qf, transformed_shapes, crop=True, filled=True)\n",
        "\n",
        "        # Replace 0 values with NaN outside transformed_shapes\n",
        "        img = np.where(img == 0, np.nan, img)\n",
        "\n",
        "\n",
        "        # New image only where qf = 1 while preserving nan values of the original image\n",
        "        #clean_img = np.where((qf == 1) | np.isnan(img), img, np.nan)\n",
        "        clean_img = np.where(qf == np.uint16(1), img, np.nan)\n",
        "        clean_img[np.isnan(clean_img)] = nodata_value\n",
        "\n",
        "        # Update the metadata for the masked image\n",
        "        img_meta = src_img.meta.copy()\n",
        "        img_meta.update({\"driver\": \"GTiff\",\n",
        "                         \"height\": img.shape[1],\n",
        "                         \"width\": img.shape[2],\n",
        "                         \"transform\": img_transform,\n",
        "                         \"nodata\": nodata_value\n",
        "                         }\n",
        "                         )\n",
        "\n",
        "        # Save the masked image into a new folder\n",
        "        output_img_path = os.path.join(output_folder, f\"masked_{os.path.basename(img_path)}\")\n",
        "\n",
        "        #print(img.dtype)\n",
        "        with rasterio.open(output_img_path, \"w\", **img_meta) as dest_img:\n",
        "            dest_img.write(clean_img[0, :, :].astype(\"int16\"), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c4dccd",
      "metadata": {
        "id": "17c4dccd"
      },
      "outputs": [],
      "source": [
        "# Sort the image and qf files based on the parsed date\n",
        "sorted_img_paths = sorted(img_paths, key=lambda path: get_date(path))\n",
        "sorted_qf_paths = sorted(qf_paths, key=lambda path: get_date(path))\n",
        "\n",
        "# Print the sorted paths\n",
        "for img_path, qf_path in zip(sorted_img_paths, sorted_qf_paths):\n",
        "    # Read the image and quality files\n",
        "    with rasterio.open(img_path) as src_img, rasterio.open(qf_path) as src_qf:\n",
        "        #print(\"Raster CRS:\", src_img.crs)\n",
        "        profile = src_img.profile\n",
        "        nodata_value = profile.get('nodata')\n",
        "\n",
        "        # Mask the image and quality files with the shapefile\n",
        "        img, img_transform = mask(src_img, transformed_shapes, crop=True, filled=True, nodata=nodata_value)\n",
        "        qf, qf_transform = mask(src_qf, transformed_shapes, crop=True, filled=True)\n",
        "\n",
        "        # Replace 0 values with NaN outside transformed_shapes\n",
        "        img = np.where(img == 0, np.nan, img)\n",
        "\n",
        "\n",
        "        # New image only where qf = 1 while preserving nan values of the original image\n",
        "        #clean_img = np.where((qf == 1) | np.isnan(img), img, np.nan)\n",
        "        clean_img = np.where(qf == np.uint16(1), img, np.nan)\n",
        "        clean_img[np.isnan(clean_img)] = nodata_value\n",
        "\n",
        "        # Update the metadata for the masked image\n",
        "        img_meta = src_img.meta.copy()\n",
        "        img_meta.update({\"driver\": \"GTiff\",\n",
        "                         \"height\": img.shape[1],\n",
        "                         \"width\": img.shape[2],\n",
        "                         \"transform\": img_transform,\n",
        "                         \"nodata\": nodata_value\n",
        "                         }\n",
        "                         )\n",
        "\n",
        "        # Save the masked image into a new folder\n",
        "        output_img_path = os.path.join(output_folder, f\"masked_{os.path.basename(img_path)}\")\n",
        "\n",
        "        #print(img.dtype)\n",
        "        with rasterio.open(output_img_path, \"w\", **img_meta) as dest_img:\n",
        "            dest_img.write(clean_img[0, :, :].astype(\"int16\"), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b09e599",
      "metadata": {
        "id": "2b09e599"
      },
      "source": [
        "_________________________________________________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93cebd26",
      "metadata": {
        "id": "93cebd26"
      },
      "source": [
        "Calcolo della media e mediana e creazione del dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "921fbf48",
      "metadata": {
        "id": "921fbf48"
      },
      "outputs": [],
      "source": [
        "def compute_statistics(src, polygon_geometry, threshold):\n",
        "    polygon = shape(polygon_geometry)\n",
        "\n",
        "    # Create a GeoJSON-like object with CRS\n",
        "    polygon_geojson = mapping(polygon)\n",
        "\n",
        "    # Mask the image using the GeoJSON-like object\n",
        "    masked_image, _ = mask(src, [polygon_geojson], crop=True)\n",
        "\n",
        "    # Since i'm working with one polygon at a time, i can check here if the covered area is > than a certain threshold\n",
        "    covered_area_pixels = np.nansum(masked_image)\n",
        "    # converts the polygon's geometric area to an area in terms of pixels.\n",
        "    total_polygon_area_pixels = polygon.area / src.res[0] * src.res[1]\n",
        "    covered_percentage = (covered_area_pixels / total_polygon_area_pixels) * 100\n",
        "\n",
        "    if covered_percentage > threshold:\n",
        "        # if the covered area is > than the threshold then it doesnt make sense compute the mean and median\n",
        "        mean_value = np.nan\n",
        "        median_value = np.nan\n",
        "    else:\n",
        "        # Compute the mean and median pixel value\n",
        "        mean_value = np.nanmean(masked_image)\n",
        "        median_value = np.nanmedian(masked_image)\n",
        "\n",
        "\n",
        "    return mean_value, median_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8b0e86",
      "metadata": {
        "id": "9d8b0e86"
      },
      "outputs": [],
      "source": [
        "def get_date(image_path):\n",
        "    date_str = os.path.basename(image_path).split(\"_\")[3][:8]\n",
        "    date_obj = pd.to_datetime(date_str, format='%Y%m%d')\n",
        "    return date_obj.date()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4b473c3",
      "metadata": {
        "id": "b4b473c3"
      },
      "outputs": [],
      "source": [
        "image_paths = sorted([os.path.join(output_folder, img) for img in os.listdir(output_folder) if img.endswith(\".tif\")], key=lambda path: get_date(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c5c055e",
      "metadata": {
        "id": "6c5c055e"
      },
      "outputs": [],
      "source": [
        "header = [\"Polygon_ID\", \"Coordinates\", \"Date\", \"Mean_NDVI_per_pixel\", \"Median_NDVI_per_pixel\"]\n",
        "rows = []\n",
        "\n",
        "polygon_df = polygon_df.sort_values(by='id')\n",
        "sorted_image_paths = sorted(image_paths, key=lambda path: get_date(path))\n",
        "\n",
        "for image_name in sorted_image_paths:\n",
        "    if image_name.endswith(\".tif\"):\n",
        "        image_path = os.path.abspath(image_name)\n",
        "        date = get_date(image_path)\n",
        "\n",
        "        # Read the image data once\n",
        "        with rasterio.open(image_path) as src:\n",
        "            # Iterate through each polygon and calculate mean pixel value\n",
        "            # edit: only if i have a non covered area > threshold\n",
        "            for _, row in polygon_df.iterrows():\n",
        "                poly_id = row['id']\n",
        "                polygon = row['geometry']\n",
        "                area = row['area']\n",
        "\n",
        "                polygon = loads(polygon)\n",
        "\n",
        "                # Calculate mean pixel value\n",
        "                mean_value, median_value = compute_statistics(src, polygon, 0.8)\n",
        "\n",
        "                # Append data as a list\n",
        "                row_data = [poly_id, polygon, date, mean_value, median_value]  # Replace 0 with the actual mean pixel value\n",
        "                rows.append(row_data)\n",
        "\n",
        "# Create DataFrame from the list of lists\n",
        "result_df = pd.DataFrame(rows, columns=header)\n",
        "result_df = result_df.sort_values(by=['Polygon_ID', 'Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac473818",
      "metadata": {
        "id": "ac473818"
      },
      "outputs": [],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47528056",
      "metadata": {
        "id": "47528056"
      },
      "source": [
        "______________________________________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26d90bc1",
      "metadata": {
        "id": "26d90bc1"
      },
      "source": [
        "#### Save dataset in CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06134b0a",
      "metadata": {
        "id": "06134b0a"
      },
      "outputs": [],
      "source": [
        "result_df.to_csv('Data/NDVI_data/NDVI_50_pc_2019.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24298a44",
      "metadata": {
        "id": "24298a44"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ndvi",
      "language": "python",
      "name": "ndvi"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}